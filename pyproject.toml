[project]
name = "lexical-benchmark"
description = "A detailed comparison between human (CDI) and model performance at the lexical level"
authors = [
    { name = "Jing Liu", email = "jing.liu@student.ru.nl" },
    { name = "CoML Team", email = "dev@cognitive-ml.fr" },
]
license = { text = "MIT License" }
readme = { file = "README.md", content-type = "text/markdown" }
requires-python = ">=3.9"
keywords = ["python"]
classifiers = [
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Development Status :: 4 - Beta",
]
dynamic = ["dependencies", "version"]

[project.urls]
documentation = "https://github.com/Jing-L97/Lexical-benchmark"
repository = "https://github.com/Jing-L97/Lexical-benchmark"

[project.scripts]
adjust-count = "lm_benchmark.adjust_count:main"
get-frequencies = "lm_benchmark.get_frequencies:main"
match-frequencies = "lm_benchmark.match_frequencies:main"
dataset-explore = "lm_benchmark.dataset_explore:main"
cf-analysis = "lm_benchmark.cf_analysis:main"
create-machine-dataset = "lm_benchmark.datasets.machine_cdi.create_dataset:main"
# Not completed ?
merge-generations = "lm_benchmark.datasets.machine_cdi.merge_generations:main"
# Not completed ?
morphology = "lm_benchmark.analysis.morphology:main"
phonemize-data = "lm_benchmark.datasets.machine_cdi.phonemize:main"
train-model = "lm_benchmark.model.train:cli_main"


[project.optional-dependencies]
dev = ["ruff", "mypy", "ipython", "jupyter"]
polyglot = ["polyglot", "pyicu", "pycld2", "morfessor"]
# Fairseq is having issues installing so lets make it optional
train = ["fairseq", "iopath"]

[build-system]
requires = ["setuptools>=45", "setuptools_scm[toml]>=6.2"]
build-backend = "setuptools.build_meta"

[tool.setuptools.dynamic]
dependencies = { file = ["requirements.txt"] }

[tool.setuptools.packages.find]
where = ["."]
include = ["lm_benchmark*"]
exclude = ["examples*", "tests*"]

[tool.mypy]
exclude = [
    'parser\.py$' # Exclude parser.py -> sly does not type-check
]

[tool.ruff]
target-version = "py311"
line-length = 120
fixable = ["ALL"]
exclude = ["parser.py"] # Exclude parser.py -> sly does not lint proper


[tool.ruff.lint]
select = ["ALL"] # Be brave use all rules

# remove the ones that make no sense
ignore = [
    "D100",    # allow top doc-string to be missing
    "D401",    # imperative mood in docstring is ambiguous
    "S603",    # allow subprocess to be called using literals
    "PLR0913", # allow functions to have more tha 12 arguments
    "TRY003",  # allow Exceptions to contain long messages
    "EM101",   # allow Exceptions to contain literals
    "ANN003",  # allow **kwargs to be without type-hints
    "D107",    # allow __init__ without docstring
    "ANN101", "ANN102",  # "self" & "cls" need no typing (rule is Deprecated)
    "T201",    # allow 'print' statements
    "TD003",   # not all todos require a issue
    "D104",    # allow scripts not to have docstring on top
    "EM102",   # allow exception to use f-strings
    "FIX002",  # allow todos
    "PLR2004", # Allow magic numbers (should be avoided, except some math contexts)
    "S311",    # No cryptography done here random is safe enough
    "PD901",   # Allow df variable name
    "COM812",  # Allow trailing comma to be missing
    "G004",    # Allow f-strings in logger (reasonable, but not here)
]


[tool.ruff.lint.flake8-import-conventions.aliases]
typing = "t"


[tool.setuptools_scm]
