{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36496ea5-fb7f-4f92-9938-d6cbe8ba9fc6",
   "metadata": {},
   "source": [
    "# STELLA Transcription Dataset\n",
    "\n",
    "The STELLA dataset...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1de1803-c9e1-4b84-9e30-0e8e3a7dea2d",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "Format Dataset into the wanted architecture. This procedure extracts audiobook transcriptions from the original dataset and sorts them into the same splits as the audio files.\n",
    "\n",
    "```\n",
    "txt\n",
    "├── LANG\n",
    "│   ├── HOUR_SPLIT\n",
    "│   │   ├── SECTION_SPLIT\n",
    "│   │   │   ├── books.txt\n",
    "│   │   │   ├── meta.json\n",
    "│   │   │   └── transcription.txt\n",
    "│   │   ├── ...\n",
    "│   ├── ...\n",
    "│   ...\n",
    "\n",
    "```\n",
    "- txt : folder containing transcriptions\n",
    "- LANG: corresponds to the given language\n",
    "- HOUR_SPLIR: corresponds to the size of the section splits in number of hours of speech,\n",
    "              formatted as (50h, 100h, ..., 3200h)\n",
    "- SECTION_SPLIT: separation of content into sections with equal amount of speech content.\n",
    "- books.txt: the list of books used for this split\n",
    "- meta.json: metadata generated during clean-up used to measure effectiveness of cleaning.\n",
    "- transcript.txt: the agregated transcripts of the audiobooks in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11b9fc4b-3337-47e2-9808-e3c5ac0ba45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Succesfuly build STELA Transcript dataset !</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mSuccesfuly build STELA Transcript dataset !\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lexical_benchmark.datasets.machine import stella\n",
    "from rich.console import Console\n",
    "\n",
    "out = Console()\n",
    "\n",
    "prep = stella.STELAPrepTranscripts(lang=\"EN\")\n",
    "with out.status(\"Processing STELA source...\"):\n",
    "    prep.build_transcript()\n",
    "\n",
    "out.print(\"Succesfuly build STELA Transcript dataset !\", style=\"bold green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e267202f-41b0-44b8-860e-0014325b6bfa",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Clean-up text to keep only clean words that can be piped through the dictionairy.\n",
    "\n",
    "RULES (Order Matters):\n",
    "1) Illustration tag removal\n",
    "2) URL removal\n",
    "3) TextNormalisation : correct accents & remove non-printable characters\n",
    "4) Trancribe numbers\n",
    "5) Remove roman numerals\n",
    "6) Fix symbols ($,€, etc..)\n",
    "7) AZFilter\n",
    "\n",
    "    * replace '-' with a space to extract hyphenated words (fifty-five -> fifty five)\n",
    "\n",
    "    * Keeps apostrophe char(*'*) to protect shorthands (ex: ain't)\n",
    "  \n",
    "    * purges everything not between [A-Z].\n",
    "\n",
    "    * lowecases everything\n",
    "8) [TODO]: Add a word normalisation (maybe?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ebc865a-0bd3-45a4-b237-bd12db002d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c167a8eab74d4f7ead7c8f701e8f9e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Succesfuly cleanned up STELA Transcript dataset !</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mSuccesfuly cleanned up STELA Transcript dataset !\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lexical_benchmark.datasets.machine import stella\n",
    "from rich.console import Console\n",
    "\n",
    "out = Console()\n",
    "\n",
    "cleaner = stella.StelaCleaner()\n",
    "cleaner.mk_clean(show_progress=True)\n",
    "out.print(\"Succesfuly cleanned up STELA Transcript dataset !\", style=\"bold green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a850a9-ef40-422b-b7b6-0967efc8de16",
   "metadata": {},
   "source": [
    "# Word Filtering\n",
    "\n",
    "Using a pre-selected lexicon we filter the corpus to separated known from unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68d5c1f6-dc95-4640-bd33-e5a9ce71191d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on:: /scratch1/projects/lexical-benchmark/v2/datasets/clean/StelaTrainDataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed cleaning of words!!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed cleaning of words!!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lexical_benchmark.datasets.machine import stella\n",
    "from lexical_benchmark.datasets import utils\n",
    "from rich.console import Console\n",
    "\n",
    "console = Console()\n",
    "dataset = stella.STELLADatasetClean()\n",
    "en_cleaner = utils.DictionairyCleaner(lang=\"EN\")\n",
    "print(f'Working on:: {dataset.root_dir}')\n",
    "\n",
    "with console.status(\"Computing clean words\"):\n",
    "    for _, (lang, hour_split, section) in enumerate(dataset.iter_all()):\n",
    "        # Create clean, unclean subsets of transcriptions\n",
    "        dataset.filter_words(lang, hour_split, section, cleaner=en_cleaner)\n",
    "\n",
    "        # Compute word frequencies of both items\n",
    "        _ = dataset.clean_words_freq(lang, hour_split, section)\n",
    "        _ = dataset.rejected_words_freq(lang, hour_split, section)\n",
    "console.print(\"Completed cleaning of words!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d53ce55-03d1-4838-9cce-c4dca3792d2e",
   "metadata": {},
   "source": [
    "## Computing cleanup stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69b315e7-490e-4e37-b269-f8fe7417022f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept 4_401_030/6_436_566 words\n",
      "Rejected 2_031_433/6_436_566 words\n",
      "----------\n",
      "We have a 31.56% of word elimination !!\n",
      "We have a 68.38% of word retention !!\n",
      "Average removal per set is   21.02%\n",
      "Average retention per set is 78.88%\n"
     ]
    }
   ],
   "source": [
    "from lexical_benchmark.datasets.machine import stella\n",
    "from lexical_benchmark.datasets import utils\n",
    "from rich.console import Console\n",
    "\n",
    "console = Console()\n",
    "dataset = stella.STELLADatasetClean()\n",
    "cleaning_stats = dataset.global_word_cleaning_stats()\n",
    "\n",
    "# Print counts\n",
    "all_count = cleaning_stats[\"all\"].sum()\n",
    "bad_count = cleaning_stats[\"bad\"].sum()\n",
    "good_count = cleaning_stats[\"good\"].sum()\n",
    "percent_bad = (bad_count / all_count)\n",
    "percent_good = (good_count / all_count)\n",
    "\n",
    "print(f\"Kept {good_count:_}/{all_count:_} words\")\n",
    "print(f\"Rejected {bad_count:_}/{all_count:_} words\")\n",
    "print(\"-\"*10)\n",
    "print(f\"We have a {percent_bad:.2%} of word elimination !!\")\n",
    "print(f\"We have a {percent_good:.2%} of word retention !!\")\n",
    "print(f\"Average removal per set is   {cleaning_stats['bad_percent'].mean():.4}%\")\n",
    "print(f\"Average retention per set is {cleaning_stats['good_percent'].mean():.4}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4727ebdc-815c-4059-b4c9-94cf15c6960f",
   "metadata": {},
   "source": [
    "### Export Global Word Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d09923d-3e27-4ff2-bfa2-89017795d37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Succesfully extracted global word frequencies !!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mSuccesfully extracted global word frequencies !!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lexical_benchmark.datasets.machine import stella\n",
    "from rich.console import Console\n",
    "\n",
    "console = Console()\n",
    "dataset = stella.STELLADatasetClean()\n",
    "\n",
    "with console.status(\"Extracting frequencies from sets...\"):\n",
    "    raw_word_freq = dataset.global_all_word_freq()\n",
    "    clean_word_freq = dataset.global_clean_word_freq()\n",
    "    rejected_word_freq = dataset.global_bad_word_freq()\n",
    "console.print(\"Succesfully extracted global word frequencies !!\", style=\"bold green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84f67fb1-539b-47be-bb33-753d497171f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'</td>\n",
       "      <td>138449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>''</td>\n",
       "      <td>7466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'''</td>\n",
       "      <td>483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>''''</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'''''</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236912</th>\n",
       "      <td>zzx</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236913</th>\n",
       "      <td>zzxl</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236914</th>\n",
       "      <td>zzzl</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236915</th>\n",
       "      <td>zzztts</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236916</th>\n",
       "      <td>zzzzzzzz</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>236917 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word    freq\n",
       "0              '  138449\n",
       "1             ''    7466\n",
       "2            '''     483\n",
       "3           ''''      98\n",
       "4          '''''      56\n",
       "...          ...     ...\n",
       "236912       zzx       7\n",
       "236913      zzxl       7\n",
       "236914      zzzl       7\n",
       "236915    zzztts       7\n",
       "236916  zzzzzzzz       7\n",
       "\n",
       "[236917 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Save word frequencies \"\"\"\n",
    "from pathlib import Path\n",
    "Path(\"stela_wf\").mkdir(exist_ok=True, parents=True)\n",
    "rejected_word_freq.to_csv(\"stela_wf/rejected.words.csv\", index=False)\n",
    "clean_word_freq.to_csv(\"stela_wf/accepted.words.csv\", index=False)\n",
    "rejected_word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9639d21c-8758-42ac-97d4-c8a06b9761a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Test Lexicon\"\"\"\n",
    "from lexical_benchmark.datasets import utils\n",
    "from lexical_benchmark.datasets.utils import lexicon\n",
    "\n",
    "en_cleaner = utils.DictionairyCleaner(lang=\"EN\")\n",
    "lexique = lexicon.Lexicon(lang=\"EN\")\n",
    "\n",
    "\"potato\" in lexique.words, \"frezdo\" in lexique.words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
