{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36496ea5-fb7f-4f92-9938-d6cbe8ba9fc6",
   "metadata": {},
   "source": [
    "# English STELLA Transcriptions Dataset\n",
    "\n",
    "The STELLA dataset...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1de1803-c9e1-4b84-9e30-0e8e3a7dea2d",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "Format Dataset into the wanted architecture. This procedure extracts audiobook transcriptions from the original dataset and sorts them into the same splits as the audio files.\n",
    "\n",
    "```\n",
    "txt\n",
    "├── LANG\n",
    "│   ├── HOUR_SPLIT\n",
    "│   │   ├── SECTION_SPLIT\n",
    "│   │   │   ├── books.txt\n",
    "│   │   │   ├── meta.json\n",
    "│   │   │   └── transcription.txt\n",
    "│   │   ├── ...\n",
    "│   ├── ...\n",
    "│   ...\n",
    "\n",
    "```\n",
    "- txt : folder containing transcriptions\n",
    "- LANG: corresponds to the given language\n",
    "- HOUR_SPLIR: corresponds to the size of the section splits in number of hours of speech,\n",
    "              formatted as (50h, 100h, ..., 3200h)\n",
    "- SECTION_SPLIT: separation of content into sections with equal amount of speech content.\n",
    "- books.txt: the list of books used for this split\n",
    "- meta.json: metadata generated during clean-up used to measure effectiveness of cleaning.\n",
    "- transcript.txt: the agregated transcripts of the audiobooks in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11b9fc4b-3337-47e2-9808-e3c5ac0ba45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Succesfuly build STELA Transcript dataset ! <span style=\"font-weight: bold\">(</span>Total time: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> minutes and <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> seconds<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Succesfuly build STELA Transcript dataset ! \u001b[1m(\u001b[0mTotal time: \u001b[1;36m2\u001b[0m minutes and \u001b[1;36m11\u001b[0m seconds\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lexical_benchmark.datasets.machine import stella\n",
    "from lexical_benchmark.utils import timed_status\n",
    "\n",
    "prep = stella.STELAPrepTranscripts(lang=\"EN\")\n",
    "with timed_status(status=\"Preping stela transcriptions...\", complete_status=\"Succesfuly build STELA Transcript dataset !\"):\n",
    "    prep.build_transcript()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e267202f-41b0-44b8-860e-0014325b6bfa",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Clean-up text to keep only clean words that can be piped through the dictionairy.\n",
    "\n",
    "RULES (Order Matters):\n",
    "1) Illustration tag removal\n",
    "2) URL removal\n",
    "3) TextNormalisation : correct accents & remove non-printable characters\n",
    "4) Trancribe numbers\n",
    "5) Remove roman numerals\n",
    "6) Fix symbols ($,€, etc..)\n",
    "7) AZFilter\n",
    "\n",
    "    * replace '-' with a space to extract hyphenated words (fifty-five -> fifty five)\n",
    "\n",
    "    * Keeps apostrophe char(*'*) to protect shorthands (ex: ain't)\n",
    "  \n",
    "    * purges everything not between [A-Z].\n",
    "\n",
    "    * lowecases everything\n",
    "8) Fix words by removing prefix and trailing quote char (')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ebc865a-0bd3-45a4-b237-bd12db002d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Succesfuly cleanned up STELA Transcript dataset ! <span style=\"font-weight: bold\">(</span>Total time: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> hour, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span> minutes and <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> seconds<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Succesfuly cleanned up STELA Transcript dataset ! \u001b[1m(\u001b[0mTotal time: \u001b[1;36m1\u001b[0m hour, \u001b[1;36m21\u001b[0m minutes and \u001b[1;36m30\u001b[0m seconds\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lexical_benchmark.datasets.machine import stella\n",
    "from lexical_benchmark.utils import timed_status\n",
    "\n",
    "cleaner = stella.StelaCleaner()\n",
    "with timed_status(status=\"Cleaning STELA Transcripts\", complete_status=\"Succesfuly cleanned up STELA Transcript dataset !\"):\n",
    "    cleaner.cleanup_raw(compute_word_freqs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a850a9-ef40-422b-b7b6-0967efc8de16",
   "metadata": {},
   "source": [
    "# Word Filtering\n",
    "\n",
    "Using a pre-selected lexicon we filter the corpus to separated known from unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68d5c1f6-dc95-4640-bd33-e5a9ce71191d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Succesfuly completed word filtering ! <span style=\"font-weight: bold\">(</span>Total time: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> minutes and <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35</span> seconds<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Succesfuly completed word filtering ! \u001b[1m(\u001b[0mTotal time: \u001b[1;36m2\u001b[0m minutes and \u001b[1;36m35\u001b[0m seconds\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lexical_benchmark.datasets.machine import stella\n",
    "from lexical_benchmark.datasets import utils\n",
    "from lexical_benchmark.utils import timed_status\n",
    "\n",
    "dataset_cleaner = stella.StelaCleaner()\n",
    "\n",
    "with timed_status(status=\"Word Filtering\", complete_status=\"Succesfuly completed word filtering !\"):\n",
    "    dataset_cleaner.mk_clean(\n",
    "        word_cleaners={\"EN\": utils.DictionairyCleaner(lang=\"EN\")},\n",
    "        compute_word_freqs=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d53ce55-03d1-4838-9cce-c4dca3792d2e",
   "metadata": {},
   "source": [
    "## Computing cleanup stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69b315e7-490e-4e37-b269-f8fe7417022f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Succesfuly extracted statistics ! <span style=\"font-weight: bold\">(</span>Total time: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span> seconds<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Succesfuly extracted statistics ! \u001b[1m(\u001b[0mTotal time: \u001b[1;36m18\u001b[0m seconds\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "==> EN-100h\n",
      "RAW:: > Number of tokens : 42_030_077, Number of types : 336_023\n",
      "CLEAN:: > Number of tokens : 41_394_999, Number of types : 132_199\n",
      "REJECT:: > Number of tokens : 635_078, Number of types : 203_824\n",
      "----------\n",
      "----------\n",
      "==> EN-1600h\n",
      "RAW:: > Number of tokens : 42_030_077, Number of types : 336_023\n",
      "CLEAN:: > Number of tokens : 41_394_999, Number of types : 132_199\n",
      "REJECT:: > Number of tokens : 635_078, Number of types : 203_824\n",
      "----------\n",
      "----------\n",
      "==> EN-200h\n",
      "RAW:: > Number of tokens : 41_928_401, Number of types : 335_905\n",
      "CLEAN:: > Number of tokens : 41_293_444, Number of types : 132_128\n",
      "REJECT:: > Number of tokens : 634_957, Number of types : 203_777\n",
      "----------\n",
      "----------\n",
      "==> EN-3200h\n",
      "RAW:: > Number of tokens : 42_030_077, Number of types : 336_023\n",
      "CLEAN:: > Number of tokens : 41_394_999, Number of types : 132_199\n",
      "REJECT:: > Number of tokens : 635_078, Number of types : 203_824\n",
      "----------\n",
      "----------\n",
      "==> EN-400h\n",
      "RAW:: > Number of tokens : 42_030_077, Number of types : 336_023\n",
      "CLEAN:: > Number of tokens : 41_394_999, Number of types : 132_199\n",
      "REJECT:: > Number of tokens : 635_078, Number of types : 203_824\n",
      "----------\n",
      "----------\n",
      "==> EN-50h\n",
      "RAW:: > Number of tokens : 42_030_077, Number of types : 336_023\n",
      "CLEAN:: > Number of tokens : 41_394_999, Number of types : 132_199\n",
      "REJECT:: > Number of tokens : 635_078, Number of types : 203_824\n",
      "----------\n",
      "----------\n",
      "==> EN-800h\n",
      "RAW:: > Number of tokens : 42_030_077, Number of types : 336_023\n",
      "CLEAN:: > Number of tokens : 41_394_999, Number of types : 132_199\n",
      "REJECT:: > Number of tokens : 635_078, Number of types : 203_824\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "from lexical_benchmark.datasets.machine import stella\n",
    "from lexical_benchmark.utils import timed_status\n",
    "from pathlib import Path\n",
    "# ------------------\n",
    "DEBUG = True\n",
    "SAVE_CSVs = True\n",
    "PRINT = True\n",
    "# ------------------\n",
    "# Configure inputs\n",
    "clean_dataset = stella.STELLADatasetClean()\n",
    "raw_dataset = stella.STELLADatasetRaw()\n",
    "meta_root = Path(\"stela_wf\") if DEBUG else clean_dataset.wf_meta_dir\n",
    "(meta_root / \"raw\").mkdir(exist_ok=True, parents=True)\n",
    "(meta_root / \"clean\").mkdir(exist_ok=True, parents=True)\n",
    "(meta_root / \"bad\").mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "stats_dict = {}\n",
    "\n",
    "with timed_status(status=\"Extracting Stats...\", complete_status=\"Succesfuly extracted statistics !\"):\n",
    "    for lang, hour_split in clean_dataset.iter_hour_splits('EN'):\n",
    "        clean_stats = clean_dataset.word_stats_by_split(lang, hour_split)\n",
    "        raw_stats = raw_dataset.word_stats_by_split(lang, hour_split)\n",
    "\n",
    "        stats_dict[f\"{lang}-{hour_split}\"] = {\n",
    "            \"raw\": raw_stats,\n",
    "            \"clean\": clean_stats\n",
    "        }\n",
    "\n",
    "        # Save Files\n",
    "        if SAVE_CSVs:\n",
    "            raw_stats.freq_map.to_csv(meta_root / f\"raw/{lang}_{hour_split}.word-freq.csv\", index=False)\n",
    "            clean_stats[\"good\"].freq_map.to_csv(meta_root / f\"clean/{lang}_{hour_split}.word-freq.csv\", index=False)\n",
    "            clean_stats[\"bad\"].freq_map.to_csv(meta_root / f\"bad/{lang}_{hour_split}.word-freq.csv\", index=False)\n",
    "\n",
    "\n",
    "# Print resuts\n",
    "if PRINT:\n",
    "    for key, value in stats_dict.items():\n",
    "        print(\"-\" * 10)\n",
    "        print(f\"==> {key}\")\n",
    "        # ALL\n",
    "        print(f\"RAW:: > Number of tokens : {value['raw'].token_nb:_}, Number of types : {value['raw'].type_nb:_}\")\n",
    "\n",
    "        # Clean\n",
    "        print(f\"CLEAN:: > Number of tokens : {value['clean']['good'].token_nb:_}, Number of types : {value['clean']['good'].type_nb:_}\")\n",
    "\n",
    "        # Rejected\n",
    "        print(f\"REJECT:: > Number of tokens : {value['clean']['bad'].token_nb:_}, Number of types : {value['clean']['bad'].type_nb:_}\")\n",
    "\n",
    "        print(\"-\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9639d21c-8758-42ac-97d4-c8a06b9761a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Test Lexicon\"\"\"\n",
    "from lexical_benchmark.datasets import utils\n",
    "from lexical_benchmark.datasets.utils import lexicon\n",
    "\n",
    "en_cleaner = utils.DictionairyCleaner(lang=\"EN\")\n",
    "lexique = lexicon.Lexicon(lang=\"EN\")\n",
    "\n",
    "\"potato\" in lexique.words, \"frezdo\" in lexique.words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
