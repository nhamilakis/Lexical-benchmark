{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da83f66b-4bfb-4852-89a8-74b77a1f54cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "from lexical_benchmark import settings\n",
    "from lexical_benchmark.datasets.human import childes\n",
    "from lexical_benchmark.datasets.human.childes import clean\n",
    "from lexical_benchmark.datasets.utils import text_cleaning\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "067f9f96-45c6-4b84-a84f-85668a6ab1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Child clean rules\n",
    "clean_rules = clean.cleaning_child_speech_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd6100dc-a6cd-45d3-8f23-d6baa1d78363",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Test clean rules on sample of files.\"\"\"\n",
    "\n",
    "files = childes.RawCHILDESFiles()\n",
    "it = files.iter(\"Eng-NA\", \"child\")\n",
    "clean_target = (settings.PATH.clean_childes / 'test')\n",
    "source = (settings.PATH.clean_childes / 'src')\n",
    "\n",
    "# MKDIR\n",
    "clean_target.mkdir(exist_ok=True, parents=True)\n",
    "source.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "def piped(line: str, *fn_list) -> str:\n",
    "    cl_line = line\n",
    "    for fn in fn_list:\n",
    "        cl_line = fn(cl_line)\n",
    "    return cl_line\n",
    "        \n",
    "for item in it:\n",
    "    # print(item.file, item.file.is_file())\n",
    "    clean_lines = [piped(line, *clean_rules) for line in item.file.read_text().splitlines()]\n",
    "    (clean_target / item.file.with_suffix(\".txt\").name).write_text(\"\\n\".join(clean_lines))\n",
    "    (source / item.file.with_suffix(\".raw\").name).write_text(item.file.read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04d777ae-7f39-4700-9849-f0ed0cadf001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['&+', '&-', '&~'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_logs = text_cleaning.WordLogger._ERROR_LOG\n",
    "error_logs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eddefdd-b658-46d4-90fb-2359e8f3e257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['parenthesis-annotation', 'bracket-annotation', '&+', '&=', '&-', '&*'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs = text_cleaning.WordLogger.export_logs()\n",
    "logs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4e09032-e92f-461e-a7be-967e6bd4a44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(logs[\"&-\"])[\"um-um\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b809248e-cbcd-472e-96cf-cb3639547991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"matches=[], counting (self.clean_pattern='&~') found: line.count(self.clean_pattern)=1 in (&~ . 204146_205981)\",\n",
       " \"matches=[], counting (self.clean_pattern='&~') found: line.count(self.clean_pattern)=1 in (&~ . 395435_395900)\",\n",
       " \"matches=[], counting (self.clean_pattern='&~') found: line.count(self.clean_pattern)=1 in (&~ . 698802_705141)\",\n",
       " \"matches=[], counting (self.clean_pattern='&~') found: line.count(self.clean_pattern)=1 in (&~ . 1139677_1140536)\",\n",
       " \"matches=[], counting (self.clean_pattern='&~') found: line.count(self.clean_pattern)=1 in (&~ . 1156002_1157326)\",\n",
       " \"matches=[], counting (self.clean_pattern='&~') found: line.count(self.clean_pattern)=1 in (&~ . 1395769_1405637)\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_logs['&~']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3e223c0-9f2d-43e1-930f-f520648631c8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaaaa\n",
      "eeee\n",
      "iiii\n",
      "ooooo\n",
      "uuuu\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Normalise text testing\"\"\"\n",
    "from lexical_benchmark.datasets.utils import text_cleaning as txt\n",
    "\n",
    "normalizer = txt.TextNormalization()\n",
    "\n",
    "def test_norm(s: str, expected_char: str):\n",
    "    normal = normalizer(s)\n",
    "    assert expected_char*len(s) == normal, f\"Expected: {expected_char*len(s)}\"\n",
    "    print(normal)\n",
    "\n",
    "\n",
    "test_norm(\"àáâãäå\",\"a\")\n",
    "test_norm(\"èéêë\",\"e\")\n",
    "test_norm(\"ìíîï\",\"i\")\n",
    "test_norm(\"òóôõö\",\"o\")\n",
    "test_norm(\"ùúûü\",\"u\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b77dfca-9728-4c0a-af5b-d45045767ed9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Test regexp for &+\"\"\"\n",
    "import re\n",
    "\n",
    "\n",
    "tag = r\"&\\+\"\n",
    "pattern = re.compile(f'{tag}\\\\S*')\n",
    "\n",
    "\n",
    "texts = [\n",
    "    \"now, what &+col\",\n",
    "    \"now, what &&col\",\n",
    "    \"well ‡ what are your plans in terms of friends (.) &+t to invite ? 208701_213055\",\n",
    "    \"yeah ‡ probably &+s Thursday after gymnastics he'll give it back „ right ?\",\n",
    "    \"<who do you> [//] &+thi who's playing with the truck here\",\n",
    "    \"you wanna knock on the &+win &+mi:rror\",\n",
    "    \"they put them on their nose and they &+ba balance them on their nose\",\n",
    "]\n",
    "\n",
    "\n",
    "for t in texts:\n",
    "    m =  pattern.findall(t)\n",
    "    print(t, \":::\", m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40886d9c-98dd-4fd8-98e6-bc1a3d19d14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f576403f044b464db98cc2bddd44210c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Completed...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Test Cleaning with custom rules.\"\"\"\n",
    "import platform\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "\n",
    "from lexical_benchmark import settings\n",
    "from lexical_benchmark.datasets.human import childes\n",
    "from lexical_benchmark.datasets.human.childes import clean\n",
    "\n",
    "assert platform.node() in settings.PATH.KNOWN_HOSTS, \"Code Running in a unknown device, you must provide custom PATH locations\"\n",
    "\n",
    "cleaner = childes.CHILDESCleaner()\n",
    "nav = childes.RawCHILDESFiles()\n",
    "it = itertools.islice(nav.iter(\"Eng-NA\", \"child\"), 100)\n",
    "target = Path('testing_files')\n",
    "target.mkdir(parents=True, exist_ok=True)\n",
    "rules = [\n",
    "    clean.BRACKET_REMOVER,\n",
    "    clean.PAREN_REMOVER,\n",
    "    clean.TEXT_NORMALISATION, \n",
    "    clean.CROCHET_REMOVER,\n",
    "]\n",
    "\n",
    "cleaner.clean_files(target, it, rules, show_progress=True)\n",
    "\n",
    "print(\"Cleanup successful...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb93f36e-3289-44d7-9b5c-899e324d9493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['@b', '@wp', 'XXX', '@c', 'YYY', '(@s:hun)', 'WWW', '-undescore', 'parenthesis-annotation', '@t', '@k', '@l', 'bracket-annotation'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lexical_benchmark.datasets.human import childes\n",
    "\n",
    "\n",
    "raw_childes = childes.RawCHILDESFiles()\n",
    "meta = raw_childes.load_clean_meta(\"Eng-NA\", \"child\")\n",
    "meta.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ac6ad3d-28e8-429f-8b72-de728125fac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'out_of': 5,\n",
       "         'lots_of': 3,\n",
       "         'thank_you': 2,\n",
       "         'kitty_cat': 2,\n",
       "         'a_lot_of': 2,\n",
       "         'Darth_Vader': 2,\n",
       "         'Grand_Moder': 1,\n",
       "         'as_well': 1,\n",
       "         'Raisin_Bran': 1,\n",
       "         'Thing_One': 1,\n",
       "         'Thing_Two': 1,\n",
       "         'Snow_White_and_the_Seven_Dwarfs': 1,\n",
       "         'At_Ats': 1})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "collections.Counter(meta['-undescore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401b85b2-651e-4450-8e8f-8a0dfbf03852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
